"""
å®Œæ•´çš„ RAG ç³»ç»Ÿå®ç°ç¤ºä¾‹
åŸºäº LangChain 1.0
é€‚ç”¨äºï¼šæ–‡æ¡£é—®ç­”ã€çŸ¥è¯†åº“æ£€ç´¢ç­‰åœºæ™¯
"""
import os
import bs4
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.tools import tool
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model

# ==================== é…ç½® ====================
# è®¾ç½® OpenAI API Keyï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™… Keyï¼‰
os.environ["OPENAI_API_KEY"] = "your-api-key-here"

# é…ç½®å‚æ•°
CONFIG = {
    "chunk_size": 1000,          # æ–‡æœ¬å—å¤§å°
    "chunk_overlap": 200,        # å—é‡å å¤§å°
    "embedding_model": "text-embedding-3-small",  # åµŒå…¥æ¨¡å‹
    "llm_model": "gpt-4o-mini",  # ç”Ÿæˆæ¨¡å‹
    "vector_db_path": "./chroma_langchain_docs",  # å‘é‡æ•°æ®åº“è·¯å¾„
    "retrieval_k": 3,            # æ£€ç´¢æ–‡æ¡£æ•°é‡
}

# ==================== ç¬¬1æ­¥ï¼šåŠ è½½æ–‡æ¡£ ====================
def load_documents():
    """ä»ç½‘é¡µåŠ è½½æ–‡æ¡£"""
    print("ğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£...")

    # ä½¿ç”¨ WebBaseLoader åŠ è½½ LangChain å®˜æ–¹æ–‡æ¡£
    loader = WebBaseLoader(
        web_paths=(
            "https://python.langchain.com/docs/tutorials/agents/",
        ),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                class_=("main",)  # åªè§£æä¸»è¦å†…å®¹
            )
        )
    )

    docs = loader.load()
    print(f"âœ“ æˆåŠŸåŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£")

    return docs


# ==================== ç¬¬2æ­¥ï¼šåˆ†å‰²æ–‡æœ¬ ====================
def split_documents(docs):
    """å°†é•¿æ–‡æ¡£åˆ†å‰²æˆå°å—"""
    print("âœ‚ï¸  æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")

    # ä½¿ç”¨é€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CONFIG["chunk_size"],
        chunk_overlap=CONFIG["chunk_overlap"],
        length_function=len,
        is_separator_regex=False,
    )

    all_splits = text_splitter.split_documents(docs)
    print(f"âœ“ æ–‡æ¡£è¢«åˆ†å‰²æˆ {len(all_splits)} ä¸ªæ–‡æœ¬å—")
    print(f"  - å¹³å‡å—å¤§å°: {sum(len(s.page_content) for s in all_splits) // len(all_splits)} å­—ç¬¦")

    return all_splits


# ==================== ç¬¬3æ­¥ï¼šåˆ›å»ºå‘é‡å­˜å‚¨ ====================
def create_vector_store(splits):
    """åˆ›å»ºå‘é‡æ•°æ®åº“"""
    print("ğŸ—„ï¸  æ­£åœ¨åˆ›å»ºå‘é‡å­˜å‚¨...")

    # åˆå§‹åŒ– Embeddings æ¨¡å‹
    embeddings = OpenAIEmbeddings(
        model=CONFIG["embedding_model"]
    )

    # åˆ›å»º Chroma å‘é‡å­˜å‚¨
    vector_store = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=CONFIG["vector_db_path"]
    )

    print(f"âœ“ å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ")
    print(f"  - å­˜å‚¨è·¯å¾„: {CONFIG['vector_db_path']}")
    print(f"  - æ–‡æ¡£æ•°é‡: {len(splits)}")

    return vector_store


# ==================== ç¬¬4æ­¥ï¼šåˆ›å»ºæ£€ç´¢å·¥å…· ====================
def create_retrieval_tool(vector_store):
    """åˆ›å»ºæ£€ç´¢å·¥å…·ä¾› Agent ä½¿ç”¨"""

    @tool(response_format="content_and_artifact")
    def retrieve_context(query: str):
        """ä» LangChain æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

        Args:
            query: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜

        Returns:
            æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å†…å®¹å’ŒåŸå§‹æ–‡æ¡£å¯¹è±¡
        """
        # ä½¿ç”¨ç›¸ä¼¼åº¦æœç´¢æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = vector_store.similarity_search(
            query,
            k=CONFIG["retrieval_k"]
        )

        # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        serialized = "\n\n".join(
            f"ã€æ–‡æ¡£ {i+1}ã€‘\n{doc.page_content}"
            for i, doc in enumerate(retrieved_docs)
        )

        return serialized, retrieved_docs

    return retrieve_context


# ==================== ç¬¬5æ­¥ï¼šåˆ›å»º RAG Agent ====================
def create_rag_agent(tools):
    """åˆ›å»º RAG Agent"""
    print("ğŸ¤– æ­£åœ¨åˆ›å»º RAG Agent...")

    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model = init_chat_model(
        CONFIG["llm_model"],
        model_provider="openai"
    )

    # å®šä¹‰ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ LangChain æ–‡æ¡£åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç†è§£å’Œä½¿ç”¨ LangChainã€‚

ä½¿ç”¨ retrieve_context å·¥å…·ä»æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚

å›ç­”è¦æ±‚ï¼š
1. å…ˆä½¿ç”¨æ£€ç´¢å·¥å…·æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
2. åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ç”Ÿæˆå‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆ
3. å¦‚æœæ£€ç´¢ä¸åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®åœ°å‘Šè¯‰ç”¨æˆ·
4. æä¾›ä»£ç ç¤ºä¾‹æ—¶ï¼Œç¡®ä¿ä»£ç å®Œæ•´ä¸”å¯è¿è¡Œ
5. ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šå’Œå‹å¥½çš„è¯­æ°”

è®°ä½ï¼šæ°¸è¿œåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚"""

    # åˆ›å»º Agent
    agent = create_agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt
    )

    print("âœ“ RAG Agent åˆ›å»ºå®Œæˆ\n")
    return agent


# ==================== ç¬¬6æ­¥ï¼šé—®ç­”äº¤äº’ ====================
def ask_question(agent, question: str):
    """å‘ RAG Agent æé—®"""
    print(f"\n{'='*70}")
    print(f"â“ é—®é¢˜: {question}")
    print('='*70)

    # è°ƒç”¨ Agent
    response = agent.invoke({
        "messages": [{"role": "user", "content": question}]
    })

    # æå–ç­”æ¡ˆ
    answer = response["messages"][-1].content

    print(f"\nğŸ’¡ å›ç­”:\n{answer}\n")
    return answer


# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("\n" + "="*70)
    print("ğŸ¦œ LangChain RAG ç³»ç»Ÿæ¼”ç¤º")
    print("="*70 + "\n")

    # æ­¥éª¤ 1: åŠ è½½æ–‡æ¡£
    docs = load_documents()

    # æ­¥éª¤ 2: åˆ†å‰²æ–‡æœ¬
    splits = split_documents(docs)

    # æ­¥éª¤ 3: åˆ›å»ºå‘é‡å­˜å‚¨
    vector_store = create_vector_store(splits)

    # æ­¥éª¤ 4: åˆ›å»ºæ£€ç´¢å·¥å…·
    retrieve_tool = create_retrieval_tool(vector_store)

    # æ­¥éª¤ 5: åˆ›å»º RAG Agent
    agent = create_rag_agent(tools=[retrieve_tool])

    # æ­¥éª¤ 6: ç¤ºä¾‹é—®ç­”
    print("\n" + "="*70)
    print("ğŸ“ å¼€å§‹ç¤ºä¾‹é—®ç­”")
    print("="*70)

    questions = [
        "ä»€ä¹ˆæ˜¯ LangChain Agentï¼Ÿ",
        "å¦‚ä½•åˆ›å»ºä¸€ä¸ª Agentï¼Ÿè¯·ç»™å‡ºä»£ç ç¤ºä¾‹",
        "LangChain æ”¯æŒå“ªäº›æ¨¡å‹æä¾›å•†ï¼Ÿ"
    ]

    for q in questions:
        ask_question(agent, q)

    print("\n" + "="*70)
    print("âœ… RAG ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
